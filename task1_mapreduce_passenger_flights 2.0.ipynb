{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "VfzjJJBsn8GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import math\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import pandas as pd\n",
        "\n",
        "# === Multi-threaded MapReduce Simulation\n",
        "# This solution mimics the parallel nature of MapReduce using Python threads.\n",
        "\n",
        "# Map Phase: Processes a chunk of rows and maps passenger flights\n",
        "def map_chunk(chunk):\n",
        "    \"\"\"\n",
        "    Map function: Converts a list of rows into key-value pairs (PassengerID, 1)\n",
        "    \"\"\"\n",
        "    return [(row[0], 1) for row in chunk]\n",
        "\n",
        "def multithreaded_map(filepath, num_threads=4):\n",
        "    \"\"\"\n",
        "    Split the dataset into chunks and process them in parallel using threads\n",
        "    \"\"\"\n",
        "    with open(filepath, mode='r') as file:\n",
        "        reader = list(csv.reader(file))\n",
        "\n",
        "    # Divide data into chunks for parallel mapping\n",
        "    chunk_size = math.ceil(len(reader) / num_threads)\n",
        "    chunks = [reader[i:i + chunk_size] for i in range(0, len(reader), chunk_size)]\n",
        "\n",
        "    mapped_results = []\n",
        "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        futures = executor.map(map_chunk, chunks)\n",
        "        for result in futures:\n",
        "            mapped_results.extend(result)\n",
        "\n",
        "    return mapped_results"
      ],
      "metadata": {
        "id": "LnRMvkmds8FC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reduce Phase: Processes a chunk of mapped pairs\n",
        "def reduce_chunk(mapped_data):\n",
        "    \"\"\"\n",
        "    Reduce function: Aggregates counts for each PassengerID in a chunk\n",
        "    \"\"\"\n",
        "    local_counts = defaultdict(int)\n",
        "    for passenger_id, count in mapped_data:\n",
        "        local_counts[passenger_id] += count\n",
        "    return local_counts\n",
        "\n",
        "def merge_counts(partials):\n",
        "    \"\"\"\n",
        "    Merge function: Combines partial counts from different threads\n",
        "    \"\"\"\n",
        "    final_counts = defaultdict(int)\n",
        "    for partial in partials:\n",
        "        for pid, count in partial.items():\n",
        "            final_counts[pid] += count\n",
        "    return final_counts\n",
        "\n",
        "def multithreaded_reduce(mapped_data, num_threads=4):\n",
        "    \"\"\"\n",
        "    Run reduce step in parallel across chunks of mapped data\n",
        "    \"\"\"\n",
        "    chunk_size = math.ceil(len(mapped_data) / num_threads)\n",
        "    chunks = [mapped_data[i:i + chunk_size] for i in range(0, len(mapped_data), chunk_size)]\n",
        "\n",
        "    partial_results = []\n",
        "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        futures = executor.map(reduce_chunk, chunks)\n",
        "        for result in futures:\n",
        "            partial_results.append(result)\n",
        "\n",
        "    return merge_counts(partial_results)"
      ],
      "metadata": {
        "id": "zIFCn-JQs-2m"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execution Starts Here\n",
        "# Set the path to your uploaded CSV file\n",
        "filepath = \"AComp_Passenger_data_no_error.csv\"  # Make sure this is uploaded in Colab\n",
        "\n",
        "# Map phase using multiple threads\n",
        "mapped_result = multithreaded_map(filepath, num_threads=4)\n",
        "\n",
        "# Reduce phase using multiple threads\n",
        "reduced_result = multithreaded_reduce(mapped_result, num_threads=4)\n",
        "\n",
        "# Find the maximum number of flights\n",
        "max_flights = max(reduced_result.values())\n",
        "\n",
        "# Get all passengers with the maximum number of flights\n",
        "top_passengers = [pid for pid, count in reduced_result.items() if count == max_flights]\n",
        "\n",
        "#\n",
        "#\n",
        "#Output Results\n",
        "print(f\"Maximum number of flights: {max_flights}\")\n",
        "print(f\"Passenger(s) with the most flights: {top_passengers}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUGT0HhOHMXV",
        "outputId": "33f6c333-ac4d-4153-d31c-f3276bc703e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum number of flights: 25\n",
            "Passenger(s) with the most flights: ['UES9151GS5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all passenger flight counts to CSV\n",
        "df_all = pd.DataFrame(reduced_result.items(), columns=[\"PassengerID\", \"FlightCount\"])\n",
        "df_all.to_csv(\"passenger_flight_counts.csv\", index=False)\n",
        "\n",
        "# Save the top passenger(s) separately\n",
        "df_top = pd.DataFrame(top_passengers, columns=[\"TopPassengerID\"])\n",
        "df_top[\"FlightCount\"] = max_flights\n",
        "df_top.to_csv(\"top_passengers.csv\", index=False)\n",
        "\n",
        "print(\"✅ Results saved as 'passenger_flight_counts.csv' and 'top_passengers.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4yOwrvFH6mo",
        "outputId": "8d93fc7f-0d6e-4863-84f0-9a6e6d9d5508"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Results saved as 'passenger_flight_counts.csv' and 'top_passengers.csv'\n"
          ]
        }
      ]
    }
  ]
}